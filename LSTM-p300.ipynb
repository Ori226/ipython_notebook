{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 740M\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import numpy as np \n",
    "import scipy.io\n",
    "import math\n",
    "import random\n",
    "import keras\n",
    "\n",
    "from pylab import *\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "\n",
    "\n",
    "import sys,os; \n",
    "# I should learn how to load libraries in a more elegant way\n",
    "sys.path.append(r'C:\\Users\\ori22_000\\Documents\\IDC-non-sync\\Thesis\\PythonApplication1\\PythonApplication1\\HelperForThesisData')\n",
    "\n",
    "import LoadThesisData\n",
    "import cPickle as pickle\n",
    "\n",
    "'''\n",
    "load the data from the mat file and save it to a \"Pickle\" file, or,\n",
    "load it if it already pickled\n",
    "'''\n",
    "load_data_from_mat_file = False\n",
    "if (load_data_from_mat_file):\n",
    "    single_subject_data = LoadThesisData.LoadSingleSubject()\n",
    "    pickle.dump( single_subject_data, open( \"c:\\\\temp\\\\single_subject.p\", \"wb\" ) )\n",
    "else:\n",
    "    single_subject_data = pickle.load( open(  \"c:\\\\temp\\\\single_subject.p\", \"rb\" ) )\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "all_samples = np.vstack((single_subject_data[0],single_subject_data[1]))\n",
    "number_of_target_examples =  single_subject_data[0].shape[0]\n",
    "\n",
    "'''\n",
    "Create the tagging column\n",
    "'''\n",
    "target_tags = np.zeros((number_of_target_examples,1))\n",
    "non_target_tags = np.ones((number_of_target_examples,1))\n",
    "all_tags = np.vstack((target_tags,non_target_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960L, 55L, 80L)\n",
      "(240L, 55L, 80L)\n",
      "[ 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'and reshape for the lstm'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = single_subject_data[0].reshape(600,55,80)\n",
    "# imshow(temp[0],interpolation='none')\n",
    "# show()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "just to validate the shape:\n",
    "'''\n",
    "all_tags.shape\n",
    "\n",
    "sample_with_tags = np.hstack((all_samples,all_tags))\n",
    "\n",
    "\n",
    "'''\n",
    "suffle the samples in order to balance between the target and non target:\n",
    "'''\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "shuffeled_samples, suffule_tags = shuffle(all_samples,all_tags, random_state=0)\n",
    "'''\n",
    "split the data to train and validation\n",
    "'''\n",
    "a_train, a_test, b_train, b_test = train_test_split(shuffeled_samples, suffule_tags, test_size=0.2, random_state=48)\n",
    "\n",
    "number_of_channels = 55\n",
    "data_traing_lstm = a_train.reshape(a_train.shape[0],number_of_channels,-1)\n",
    "\n",
    "data_testing_lstm = a_test.reshape(a_test.shape[0],number_of_channels,-1)\n",
    "\n",
    "print (data_traing_lstm.shape)\n",
    "print (data_testing_lstm.shape)\n",
    "print (b_train[0])\n",
    "'and reshape for the lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.stats\n",
    "from scipy.stats import futil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "input_dimesion = shuffeled_samples.shape[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\theano\\theano\\scan_module\\scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "'''\n",
    "define the neural network model:\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(LSTM(55, 100,return_sequences=True))\n",
    "# model.add(LSTM(100, 100,return_sequences=True))\n",
    "# model.add(LSTM(100, 100,return_sequences=True))\n",
    "# model.add(LSTM(100, 1))\n",
    "# model.add(Activation('sigmoid'))\n",
    "# # # model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# '''\n",
    "# define the optimization function and compile it:\n",
    "# '''\n",
    "\n",
    "# #sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "# rmsprop = RMSprop(lr=0.0001, rho=0.5, epsilon=1e-6)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='rmsprop',class_mode='binary')\n",
    "\n",
    "'''\n",
    "train the mocdel\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "test the model\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(LSTM(55, 100,return_sequences=True))\n",
    "model2.add(LSTM(100, 100,return_sequences=True))\n",
    "model2.add(LSTM(100, 100,return_sequences=True))\n",
    "model2.add(LSTM(100, 1))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='rmsprop',class_mode='binary')\n",
    "\n",
    "original_weights = model2.get_weights();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 11s - loss: 0.6680 - acc: 0.5936 - val_loss: 0.6470 - val_acc: 0.6296\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6343 - acc: 0.6739 - val_loss: 0.6048 - val_acc: 0.7407\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.5826 - acc: 0.7654 - val_loss: 0.6612 - val_acc: 0.6019\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.5792 - acc: 0.7521 - val_loss: 0.6110 - val_acc: 0.6759\n",
      "Epoch 4\n",
      "972/972 [==============================] - 11s - loss: 0.5402 - acc: 0.8025 - val_loss: 0.4897 - val_acc: 0.8704\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.4992 - acc: 0.8354 - val_loss: 0.5325 - val_acc: 0.7778\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.5087 - acc: 0.8076 - val_loss: 0.4752 - val_acc: 0.8333\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.4068 - acc: 0.9146 - val_loss: 0.4247 - val_acc: 0.8981\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.4048 - acc: 0.9115 - val_loss: 0.3893 - val_acc: 0.9259\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.4217 - acc: 0.8848 - val_loss: 0.4713 - val_acc: 0.8611\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.3680 - acc: 0.9496 - val_loss: 0.4226 - val_acc: 0.8889\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.3711 - acc: 0.9414 - val_loss: 0.3772 - val_acc: 0.9444\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.3539 - acc: 0.9578 - val_loss: 0.4532 - val_acc: 0.8611\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.3555 - acc: 0.9588 - val_loss: 0.4417 - val_acc: 0.8889\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3518 - acc: 0.9650 - val_loss: 0.3869 - val_acc: 0.9352\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3314 - acc: 0.9835 - val_loss: 0.4076 - val_acc: 0.9074\n",
      "Epoch 16\n",
      "972/972 [==============================] - 11s - loss: 0.3354 - acc: 0.9794 - val_loss: 0.3895 - val_acc: 0.9167\n",
      "Epoch 17\n",
      "972/972 [==============================] - 11s - loss: 0.3815 - acc: 0.9290 - val_loss: 0.3727 - val_acc: 0.9444\n",
      "Epoch 18\n",
      "972/972 [==============================] - 11s - loss: 0.3608 - acc: 0.9527 - val_loss: 0.3881 - val_acc: 0.9259\n",
      "Epoch 19\n",
      "972/972 [==============================] - 11s - loss: 0.3323 - acc: 0.9815 - val_loss: 0.3654 - val_acc: 0.9444\n",
      "Epoch 20\n",
      "972/972 [==============================] - 11s - loss: 0.3579 - acc: 0.9516 - val_loss: 0.3868 - val_acc: 0.9352\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3276 - acc: 0.9866 - val_loss: 0.3614 - val_acc: 0.9537\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3214 - acc: 0.9928 - val_loss: 0.3719 - val_acc: 0.9352\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3390 - acc: 0.9763 - val_loss: 0.3597 - val_acc: 0.9537\n",
      "Epoch 24\n",
      "972/972 [==============================] - 11s - loss: 0.3166 - acc: 0.9979 - val_loss: 0.3687 - val_acc: 0.9444\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3157 - acc: 0.9979 - val_loss: 0.3626 - val_acc: 0.9444\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.3155 - acc: 0.9979 - val_loss: 0.3576 - val_acc: 0.9537\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3612 - val_acc: 0.9444\n",
      "Epoch 28\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3668 - val_acc: 0.9444\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3668 - val_acc: 0.9444\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3685 - val_acc: 0.9444\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3710 - val_acc: 0.9444\n",
      "Epoch 32\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3741 - val_acc: 0.9352\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3742 - val_acc: 0.9352\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3757 - val_acc: 0.9352\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3755 - val_acc: 0.9259\n",
      "Epoch 36\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3765 - val_acc: 0.9259\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3776 - val_acc: 0.9259\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3780 - val_acc: 0.9259\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3784 - val_acc: 0.9259\n",
      "120/120 [==============================] - 0s\n",
      "[0.33178088068962097, 0.98333333333333328]\n",
      "120/120 [==============================] - 0s\n",
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 11s - loss: 0.6679 - acc: 0.5957 - val_loss: 0.6502 - val_acc: 0.6204\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6231 - acc: 0.6903 - val_loss: 0.6625 - val_acc: 0.6019\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.6049 - acc: 0.7315 - val_loss: 0.5818 - val_acc: 0.7593\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.5777 - acc: 0.7675 - val_loss: 0.5225 - val_acc: 0.8333\n",
      "Epoch 4\n",
      "972/972 [==============================] - 11s - loss: 0.5417 - acc: 0.7912 - val_loss: 0.5772 - val_acc: 0.7407\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.4993 - acc: 0.8447 - val_loss: 0.4689 - val_acc: 0.8889\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.4539 - acc: 0.8755 - val_loss: 0.4624 - val_acc: 0.8796\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.4429 - acc: 0.8714 - val_loss: 0.4235 - val_acc: 0.9167\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.4236 - acc: 0.8879 - val_loss: 0.5293 - val_acc: 0.7870\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.4783 - acc: 0.8313 - val_loss: 0.4137 - val_acc: 0.9074\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.4364 - acc: 0.8786 - val_loss: 0.4705 - val_acc: 0.8241\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.3639 - acc: 0.9537 - val_loss: 0.4918 - val_acc: 0.8333\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.3951 - acc: 0.9167 - val_loss: 0.3673 - val_acc: 0.9444\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.3815 - acc: 0.9270 - val_loss: 0.4301 - val_acc: 0.8981\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3643 - acc: 0.9506 - val_loss: 0.3743 - val_acc: 0.9444\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3341 - acc: 0.9835 - val_loss: 0.4353 - val_acc: 0.8611\n",
      "Epoch 16\n",
      "972/972 [==============================] - 11s - loss: 0.3922 - acc: 0.9156 - val_loss: 0.3844 - val_acc: 0.9352\n",
      "Epoch 17\n",
      "972/972 [==============================] - 11s - loss: 0.3460 - acc: 0.9681 - val_loss: 0.3717 - val_acc: 0.9444\n",
      "Epoch 18\n",
      "972/972 [==============================] - 11s - loss: 0.3283 - acc: 0.9866 - val_loss: 0.3837 - val_acc: 0.9259\n",
      "Epoch 19\n",
      "972/972 [==============================] - 11s - loss: 0.3551 - acc: 0.9578 - val_loss: 0.3711 - val_acc: 0.9352\n",
      "Epoch 20\n",
      "972/972 [==============================] - 12s - loss: 0.3239 - acc: 0.9918 - val_loss: 0.3567 - val_acc: 0.9537\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3219 - acc: 0.9928 - val_loss: 0.3642 - val_acc: 0.9537\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3424 - acc: 0.9712 - val_loss: 0.4093 - val_acc: 0.9074\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3505 - acc: 0.9630 - val_loss: 0.3691 - val_acc: 0.9537\n",
      "Epoch 24\n",
      "972/972 [==============================] - 11s - loss: 0.3182 - acc: 0.9969 - val_loss: 0.3528 - val_acc: 0.9630\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3164 - acc: 0.9969 - val_loss: 0.3509 - val_acc: 0.9630\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.3155 - acc: 0.9979 - val_loss: 0.3531 - val_acc: 0.9537\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3155 - acc: 0.9979 - val_loss: 0.3527 - val_acc: 0.9537\n",
      "Epoch 28\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3456 - val_acc: 0.9630\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3810 - acc: 0.9300 - val_loss: 0.3827 - val_acc: 0.9352\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3283 - acc: 0.9856 - val_loss: 0.3884 - val_acc: 0.9167\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3174 - acc: 0.9959 - val_loss: 0.3508 - val_acc: 0.9630\n",
      "Epoch 32\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3921 - val_acc: 0.9167\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3619 - acc: 0.9465 - val_loss: 0.3331 - val_acc: 0.9815\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3195 - acc: 0.9949 - val_loss: 0.3484 - val_acc: 0.9630\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3168 - acc: 0.9969 - val_loss: 0.3400 - val_acc: 0.9722\n",
      "Epoch 36\n",
      "972/972 [==============================] - 11s - loss: 0.3266 - acc: 0.9866 - val_loss: 0.3902 - val_acc: 0.9167\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3253 - acc: 0.9877 - val_loss: 0.3246 - val_acc: 0.9815\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3149 - acc: 0.9990 - val_loss: 0.3356 - val_acc: 0.9815\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3146 - acc: 0.9990 - val_loss: 0.3295 - val_acc: 0.9815\n",
      "120/120 [==============================] - 0s\n",
      "[0.36126944422721863, 0.94999999999999996]\n",
      "120/120 [==============================] - 0s\n",
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 11s - loss: 0.6702 - acc: 0.5988 - val_loss: 0.6550 - val_acc: 0.6019\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6242 - acc: 0.6842 - val_loss: 0.5927 - val_acc: 0.7685\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.6051 - acc: 0.7274 - val_loss: 0.6194 - val_acc: 0.6944\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.5737 - acc: 0.7593 - val_loss: 0.6090 - val_acc: 0.6944\n",
      "Epoch 4\n",
      "972/972 [==============================] - 11s - loss: 0.5328 - acc: 0.8138 - val_loss: 0.5547 - val_acc: 0.7778\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.5389 - acc: 0.7767 - val_loss: 0.5528 - val_acc: 0.7593\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.5136 - acc: 0.8128 - val_loss: 0.4928 - val_acc: 0.8241\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.4652 - acc: 0.8529 - val_loss: 0.5304 - val_acc: 0.7870\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.4321 - acc: 0.8868 - val_loss: 0.6185 - val_acc: 0.6944\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.4207 - acc: 0.8981 - val_loss: 0.4422 - val_acc: 0.8704\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.4609 - acc: 0.8457 - val_loss: 0.5800 - val_acc: 0.7130\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.3985 - acc: 0.9239 - val_loss: 0.3975 - val_acc: 0.9259\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.3540 - acc: 0.9650 - val_loss: 0.3753 - val_acc: 0.9352\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.3719 - acc: 0.9434 - val_loss: 0.3794 - val_acc: 0.9259\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3686 - acc: 0.9434 - val_loss: 0.3912 - val_acc: 0.9167\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3371 - acc: 0.9763 - val_loss: 0.3759 - val_acc: 0.9352\n",
      "Epoch 16\n",
      "972/972 [==============================] - 16s - loss: 0.3548 - acc: 0.9568 - val_loss: 0.3563 - val_acc: 0.9630\n",
      "Epoch 17\n",
      "972/972 [==============================] - 12s - loss: 0.3722 - acc: 0.9393 - val_loss: 0.4391 - val_acc: 0.8704\n",
      "Epoch 18\n",
      "972/972 [==============================] - 12s - loss: 0.3570 - acc: 0.9558 - val_loss: 0.6662 - val_acc: 0.6296\n",
      "Epoch 19\n",
      "972/972 [==============================] - 13s - loss: 0.4028 - acc: 0.9053 - val_loss: 0.4029 - val_acc: 0.9074\n",
      "Epoch 20\n",
      "972/972 [==============================] - 11s - loss: 0.3493 - acc: 0.9640 - val_loss: 0.3843 - val_acc: 0.9259\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3429 - acc: 0.9712 - val_loss: 0.3770 - val_acc: 0.9352\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3380 - acc: 0.9743 - val_loss: 0.3852 - val_acc: 0.9259\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3334 - acc: 0.9815 - val_loss: 0.3613 - val_acc: 0.9537\n",
      "Epoch 24\n",
      "972/972 [==============================] - 11s - loss: 0.3306 - acc: 0.9825 - val_loss: 0.3504 - val_acc: 0.9630\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3570 - acc: 0.9558 - val_loss: 0.3988 - val_acc: 0.9074\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.3557 - acc: 0.9568 - val_loss: 0.4156 - val_acc: 0.8981\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3278 - acc: 0.9856 - val_loss: 0.3422 - val_acc: 0.9630\n",
      "Epoch 28\n",
      "972/972 [==============================] - 11s - loss: 0.3199 - acc: 0.9928 - val_loss: 0.3676 - val_acc: 0.9352\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3350 - acc: 0.9784 - val_loss: 0.3375 - val_acc: 0.9815\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3163 - acc: 0.9979 - val_loss: 0.3404 - val_acc: 0.9722\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3145 - acc: 0.9990 - val_loss: 0.3407 - val_acc: 0.9722\n",
      "Epoch 32\n",
      "972/972 [==============================] - 11s - loss: 0.3144 - acc: 0.9990 - val_loss: 0.3414 - val_acc: 0.9722\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3136 - acc: 1.0000 - val_loss: 0.3976 - val_acc: 0.9167\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3601 - acc: 0.9537 - val_loss: 0.3472 - val_acc: 0.9630\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3148 - acc: 0.9990 - val_loss: 0.3418 - val_acc: 0.9722\n",
      "Epoch 36\n",
      "972/972 [==============================] - 11s - loss: 0.3134 - acc: 1.0000 - val_loss: 0.3387 - val_acc: 0.9722\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3133 - acc: 1.0000 - val_loss: 0.3390 - val_acc: 0.9722\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3133 - acc: 1.0000 - val_loss: 0.3392 - val_acc: 0.9722\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3133 - acc: 1.0000 - val_loss: 0.3394 - val_acc: 0.9722\n",
      "120/120 [==============================] - 0s\n",
      "[0.35044729709625244, 0.96666666666666667]\n",
      "120/120 [==============================] - 0s\n",
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 11s - loss: 0.6803 - acc: 0.5730 - val_loss: 0.6260 - val_acc: 0.7407\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6256 - acc: 0.6996 - val_loss: 0.5970 - val_acc: 0.7593\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.5849 - acc: 0.7654 - val_loss: 0.6026 - val_acc: 0.6944\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.5504 - acc: 0.7963 - val_loss: 0.5599 - val_acc: 0.7685\n",
      "Epoch 4\n",
      "972/972 [==============================] - 11s - loss: 0.5141 - acc: 0.8272 - val_loss: 0.6948 - val_acc: 0.5648\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.4987 - acc: 0.8251 - val_loss: 0.5381 - val_acc: 0.7870\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.4829 - acc: 0.8374 - val_loss: 0.4291 - val_acc: 0.8889\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.4122 - acc: 0.9033 - val_loss: 0.4307 - val_acc: 0.8796\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.3586 - acc: 0.9578 - val_loss: 0.4220 - val_acc: 0.8889\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.3869 - acc: 0.9259 - val_loss: 0.5881 - val_acc: 0.7130\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.3883 - acc: 0.9228 - val_loss: 0.3539 - val_acc: 0.9630\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.3394 - acc: 0.9743 - val_loss: 0.3611 - val_acc: 0.9630\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.3625 - acc: 0.9516 - val_loss: 0.3697 - val_acc: 0.9537\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.3266 - acc: 0.9866 - val_loss: 0.3532 - val_acc: 0.9537\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3178 - acc: 0.9969 - val_loss: 0.3500 - val_acc: 0.9630\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3891 - acc: 0.9218 - val_loss: 0.3832 - val_acc: 0.9352\n",
      "Epoch 16\n",
      "972/972 [==============================] - 11s - loss: 0.3183 - acc: 0.9969 - val_loss: 0.3628 - val_acc: 0.9537\n",
      "Epoch 17\n",
      "972/972 [==============================] - 11s - loss: 0.3159 - acc: 0.9979 - val_loss: 0.3605 - val_acc: 0.9537\n",
      "Epoch 18\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3533 - val_acc: 0.9630\n",
      "Epoch 19\n",
      "972/972 [==============================] - 11s - loss: 0.3145 - acc: 0.9990 - val_loss: 0.3514 - val_acc: 0.9537\n",
      "Epoch 20\n",
      "972/972 [==============================] - 11s - loss: 0.3144 - acc: 0.9990 - val_loss: 0.3528 - val_acc: 0.9537\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3144 - acc: 0.9990 - val_loss: 0.3564 - val_acc: 0.9537\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3144 - acc: 0.9990 - val_loss: 0.3574 - val_acc: 0.9537\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3527 - val_acc: 0.9537\n",
      "Epoch 24\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3578 - val_acc: 0.9537\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3592 - val_acc: 0.9537\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3598 - val_acc: 0.9537\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3590 - val_acc: 0.9537\n",
      "Epoch 28\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3598 - val_acc: 0.9537\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3597 - val_acc: 0.9537\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3597 - val_acc: 0.9537\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3600 - val_acc: 0.9537\n",
      "Epoch 32\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3597 - val_acc: 0.9537\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3598 - val_acc: 0.9537\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3600 - val_acc: 0.9537\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3599 - val_acc: 0.9537\n",
      "Epoch 36\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3597 - val_acc: 0.9537\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3597 - val_acc: 0.9537\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3596 - val_acc: 0.9537\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3600 - val_acc: 0.9537\n",
      "120/120 [==============================] - 0s\n",
      "[0.39266771078109741, 0.91666666666666663]\n",
      "120/120 [==============================] - 0s\n",
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 11s - loss: 0.6792 - acc: 0.5648 - val_loss: 0.6678 - val_acc: 0.5926\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6282 - acc: 0.6852 - val_loss: 0.6434 - val_acc: 0.6481\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.6224 - acc: 0.7016 - val_loss: 0.6002 - val_acc: 0.7407\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.5771 - acc: 0.7706 - val_loss: 0.7182 - val_acc: 0.5278\n",
      "Epoch 4\n",
      "972/972 [==============================] - 11s - loss: 0.5890 - acc: 0.7325 - val_loss: 0.5880 - val_acc: 0.7315\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.5171 - acc: 0.8230 - val_loss: 0.5384 - val_acc: 0.7778\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.5107 - acc: 0.8220 - val_loss: 0.5661 - val_acc: 0.7593\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.4683 - acc: 0.8642 - val_loss: 0.4800 - val_acc: 0.8241\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.4375 - acc: 0.8899 - val_loss: 0.4896 - val_acc: 0.8148\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.4303 - acc: 0.8920 - val_loss: 0.5733 - val_acc: 0.7315\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.4117 - acc: 0.9074 - val_loss: 0.4265 - val_acc: 0.8889\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.4075 - acc: 0.9105 - val_loss: 0.5163 - val_acc: 0.7870\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.4055 - acc: 0.9095 - val_loss: 0.4039 - val_acc: 0.9074\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.3735 - acc: 0.9414 - val_loss: 0.4041 - val_acc: 0.8981\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3464 - acc: 0.9660 - val_loss: 0.3773 - val_acc: 0.9352\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3885 - acc: 0.9259 - val_loss: 0.3707 - val_acc: 0.9444\n",
      "Epoch 16\n",
      "972/972 [==============================] - 11s - loss: 0.3261 - acc: 0.9887 - val_loss: 0.5127 - val_acc: 0.8056\n",
      "Epoch 17\n",
      "972/972 [==============================] - 11s - loss: 0.4021 - acc: 0.9105 - val_loss: 0.3619 - val_acc: 0.9444\n",
      "Epoch 18\n",
      "972/972 [==============================] - 11s - loss: 0.3250 - acc: 0.9907 - val_loss: 0.3566 - val_acc: 0.9537\n",
      "Epoch 19\n",
      "972/972 [==============================] - 11s - loss: 0.3183 - acc: 0.9959 - val_loss: 0.3753 - val_acc: 0.9352\n",
      "Epoch 20\n",
      "972/972 [==============================] - 11s - loss: 0.3958 - acc: 0.9146 - val_loss: 0.4493 - val_acc: 0.8519\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3335 - acc: 0.9815 - val_loss: 0.3459 - val_acc: 0.9722\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3236 - acc: 0.9897 - val_loss: 0.3596 - val_acc: 0.9444\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3521 - acc: 0.9588 - val_loss: 0.4143 - val_acc: 0.8981\n",
      "Epoch 24\n",
      "972/972 [==============================] - 11s - loss: 0.3536 - acc: 0.9578 - val_loss: 0.4599 - val_acc: 0.8611\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3768 - acc: 0.9362 - val_loss: 0.3611 - val_acc: 0.9537\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.3293 - acc: 0.9835 - val_loss: 0.3692 - val_acc: 0.9352\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3165 - acc: 0.9969 - val_loss: 0.3688 - val_acc: 0.9352\n",
      "Epoch 28\n",
      "972/972 [==============================] - 11s - loss: 0.3163 - acc: 0.9969 - val_loss: 0.3678 - val_acc: 0.9352\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3161 - acc: 0.9969 - val_loss: 0.3673 - val_acc: 0.9352\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3158 - acc: 0.9979 - val_loss: 0.3672 - val_acc: 0.9352\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3156 - acc: 0.9979 - val_loss: 0.3693 - val_acc: 0.9352\n",
      "Epoch 32\n",
      "972/972 [==============================] - 11s - loss: 0.3155 - acc: 0.9979 - val_loss: 0.3724 - val_acc: 0.9352\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3751 - acc: 0.9352 - val_loss: 0.4247 - val_acc: 0.8704\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3279 - acc: 0.9866 - val_loss: 0.3723 - val_acc: 0.9259\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3156 - acc: 0.9979 - val_loss: 0.3676 - val_acc: 0.9352\n",
      "Epoch 36\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3583 - val_acc: 0.9537\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3144 - acc: 0.9990 - val_loss: 0.3551 - val_acc: 0.9630\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3144 - acc: 0.9990 - val_loss: 0.3560 - val_acc: 0.9537\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3556 - val_acc: 0.9537\n",
      "120/120 [==============================] - 0s\n",
      "[0.3518383800983429, 0.95833333333333337]\n",
      "120/120 [==============================] - 0s\n",
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 11s - loss: 0.6852 - acc: 0.5535 - val_loss: 0.6235 - val_acc: 0.7407\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6213 - acc: 0.7027 - val_loss: 0.5909 - val_acc: 0.7685\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.5932 - acc: 0.7469 - val_loss: 0.5726 - val_acc: 0.7593\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.5569 - acc: 0.7798 - val_loss: 0.5530 - val_acc: 0.7963\n",
      "Epoch 4\n",
      "972/972 [==============================] - 12s - loss: 0.5318 - acc: 0.7963 - val_loss: 0.4899 - val_acc: 0.8426\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.4967 - acc: 0.8272 - val_loss: 0.5914 - val_acc: 0.7222\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.5808 - acc: 0.7356 - val_loss: 0.5986 - val_acc: 0.6852\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.5220 - acc: 0.7994 - val_loss: 0.5985 - val_acc: 0.7037\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.4966 - acc: 0.8302 - val_loss: 0.5002 - val_acc: 0.8241\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.4656 - acc: 0.8632 - val_loss: 0.4772 - val_acc: 0.8333\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.4315 - acc: 0.9002 - val_loss: 0.4929 - val_acc: 0.8241\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.4128 - acc: 0.9136 - val_loss: 0.4468 - val_acc: 0.8704\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.4117 - acc: 0.9084 - val_loss: 0.4633 - val_acc: 0.8611\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.3806 - acc: 0.9414 - val_loss: 0.4188 - val_acc: 0.8889\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3808 - acc: 0.9342 - val_loss: 0.6195 - val_acc: 0.6296\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3974 - acc: 0.9208 - val_loss: 0.4041 - val_acc: 0.9167\n",
      "Epoch 16\n",
      "972/972 [==============================] - 11s - loss: 0.3865 - acc: 0.9280 - val_loss: 0.4794 - val_acc: 0.8148\n",
      "Epoch 17\n",
      "972/972 [==============================] - 11s - loss: 0.3709 - acc: 0.9414 - val_loss: 0.4491 - val_acc: 0.8426\n",
      "Epoch 18\n",
      "972/972 [==============================] - 11s - loss: 0.3491 - acc: 0.9640 - val_loss: 0.3572 - val_acc: 0.9630\n",
      "Epoch 19\n",
      "972/972 [==============================] - 11s - loss: 0.3870 - acc: 0.9239 - val_loss: 0.4052 - val_acc: 0.9167\n",
      "Epoch 20\n",
      "972/972 [==============================] - 11s - loss: 0.3439 - acc: 0.9712 - val_loss: 0.3582 - val_acc: 0.9630\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3446 - acc: 0.9681 - val_loss: 0.4281 - val_acc: 0.8796\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3657 - acc: 0.9465 - val_loss: 0.3995 - val_acc: 0.9074\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3617 - acc: 0.9516 - val_loss: 0.5040 - val_acc: 0.8056\n",
      "Epoch 24\n",
      "972/972 [==============================] - 11s - loss: 0.3586 - acc: 0.9558 - val_loss: 0.4035 - val_acc: 0.8981\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3243 - acc: 0.9897 - val_loss: 0.4726 - val_acc: 0.8333\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.3883 - acc: 0.9228 - val_loss: 0.3735 - val_acc: 0.9352\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3231 - acc: 0.9907 - val_loss: 0.3556 - val_acc: 0.9630\n",
      "Epoch 28\n",
      "972/972 [==============================] - 11s - loss: 0.3166 - acc: 0.9979 - val_loss: 0.3470 - val_acc: 0.9630\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3158 - acc: 0.9979 - val_loss: 0.3510 - val_acc: 0.9537\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3156 - acc: 0.9979 - val_loss: 0.3472 - val_acc: 0.9630\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3155 - acc: 0.9979 - val_loss: 0.3489 - val_acc: 0.9537\n",
      "Epoch 32\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3477 - val_acc: 0.9630\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3485 - val_acc: 0.9630\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3474 - val_acc: 0.9630\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3477 - val_acc: 0.9630\n",
      "Epoch 36\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3477 - val_acc: 0.9630\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3493 - val_acc: 0.9630\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3499 - val_acc: 0.9537\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3482 - val_acc: 0.9630\n",
      "120/120 [==============================] - 0s\n",
      "[0.33986169099807739, 0.97499999999999998]\n",
      "120/120 [==============================] - 0s\n",
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 17s - loss: 0.6903 - acc: 0.5473 - val_loss: 0.6483 - val_acc: 0.6667\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6384 - acc: 0.6708 - val_loss: 0.6288 - val_acc: 0.6944\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.6137 - acc: 0.6986 - val_loss: 0.5683 - val_acc: 0.7778\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.5719 - acc: 0.7788 - val_loss: 0.5476 - val_acc: 0.7963\n",
      "Epoch 4\n",
      "972/972 [==============================] - 11s - loss: 0.5367 - acc: 0.8045 - val_loss: 0.5701 - val_acc: 0.7500\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.5438 - acc: 0.7819 - val_loss: 0.5315 - val_acc: 0.7963\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.4631 - acc: 0.8807 - val_loss: 0.4737 - val_acc: 0.8704\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.4489 - acc: 0.8745 - val_loss: 0.4790 - val_acc: 0.8333\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.4097 - acc: 0.9084 - val_loss: 0.4628 - val_acc: 0.8333\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.4062 - acc: 0.9084 - val_loss: 0.4175 - val_acc: 0.8981\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.3647 - acc: 0.9527 - val_loss: 0.4185 - val_acc: 0.8889\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.3796 - acc: 0.9342 - val_loss: 0.4231 - val_acc: 0.8796\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.3657 - acc: 0.9475 - val_loss: 0.3971 - val_acc: 0.9167\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.3766 - acc: 0.9342 - val_loss: 0.4834 - val_acc: 0.8426\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3822 - acc: 0.9311 - val_loss: 0.4104 - val_acc: 0.8981\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3648 - acc: 0.9486 - val_loss: 0.3840 - val_acc: 0.9259\n",
      "Epoch 16\n",
      "972/972 [==============================] - 11s - loss: 0.3316 - acc: 0.9835 - val_loss: 0.5864 - val_acc: 0.7222\n",
      "Epoch 17\n",
      "972/972 [==============================] - 11s - loss: 0.3828 - acc: 0.9300 - val_loss: 0.3920 - val_acc: 0.9259\n",
      "Epoch 18\n",
      "972/972 [==============================] - 11s - loss: 0.3455 - acc: 0.9650 - val_loss: 0.4111 - val_acc: 0.8981\n",
      "Epoch 19\n",
      "972/972 [==============================] - 11s - loss: 0.3405 - acc: 0.9733 - val_loss: 0.4236 - val_acc: 0.8889\n",
      "Epoch 20\n",
      "972/972 [==============================] - 11s - loss: 0.3342 - acc: 0.9805 - val_loss: 0.3701 - val_acc: 0.9444\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3281 - acc: 0.9846 - val_loss: 0.3609 - val_acc: 0.9537\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3305 - acc: 0.9825 - val_loss: 0.5807 - val_acc: 0.7130\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3686 - acc: 0.9444 - val_loss: 0.3827 - val_acc: 0.9259\n",
      "Epoch 24\n",
      "972/972 [==============================] - 11s - loss: 0.3294 - acc: 0.9846 - val_loss: 0.3805 - val_acc: 0.9259\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3430 - acc: 0.9691 - val_loss: 0.5292 - val_acc: 0.7778\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.4001 - acc: 0.9084 - val_loss: 0.3681 - val_acc: 0.9444\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3459 - acc: 0.9640 - val_loss: 0.3763 - val_acc: 0.9352\n",
      "Epoch 28\n",
      "972/972 [==============================] - 11s - loss: 0.3393 - acc: 0.9702 - val_loss: 0.3715 - val_acc: 0.9444\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3572 - acc: 0.9537 - val_loss: 0.3599 - val_acc: 0.9537\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3267 - acc: 0.9877 - val_loss: 0.3667 - val_acc: 0.9444\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3331 - acc: 0.9815 - val_loss: 0.3350 - val_acc: 0.9815\n",
      "Epoch 32\n",
      "972/972 [==============================] - 11s - loss: 0.3158 - acc: 0.9979 - val_loss: 0.3348 - val_acc: 0.9815\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3155 - acc: 0.9979 - val_loss: 0.3344 - val_acc: 0.9815\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3339 - val_acc: 0.9815\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3506 - val_acc: 0.9630\n",
      "Epoch 36\n",
      "972/972 [==============================] - 12s - loss: 0.3147 - acc: 0.9990 - val_loss: 0.3376 - val_acc: 0.9722\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3359 - val_acc: 0.9815\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3350 - val_acc: 0.9815\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3349 - val_acc: 0.9815\n",
      "120/120 [==============================] - 0s\n",
      "[0.33176988363265991, 0.98333333333333328]\n",
      "120/120 [==============================] - 0s\n",
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 11s - loss: 0.6610 - acc: 0.6101 - val_loss: 0.6644 - val_acc: 0.6111\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6253 - acc: 0.6831 - val_loss: 0.6151 - val_acc: 0.7222\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.5892 - acc: 0.7377 - val_loss: 0.6377 - val_acc: 0.6389\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.5238 - acc: 0.8302 - val_loss: 0.6962 - val_acc: 0.5556\n",
      "Epoch 4\n",
      "972/972 [==============================] - 11s - loss: 0.5214 - acc: 0.8025 - val_loss: 0.5345 - val_acc: 0.7778\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.5485 - acc: 0.7654 - val_loss: 0.6273 - val_acc: 0.6759\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.4902 - acc: 0.8241 - val_loss: 0.5259 - val_acc: 0.7963\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.4262 - acc: 0.8930 - val_loss: 0.7550 - val_acc: 0.5185\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.4521 - acc: 0.8580 - val_loss: 0.4689 - val_acc: 0.8241\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.3925 - acc: 0.9208 - val_loss: 0.5885 - val_acc: 0.7222\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.4142 - acc: 0.8981 - val_loss: 0.4548 - val_acc: 0.8519\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.3780 - acc: 0.9383 - val_loss: 0.4181 - val_acc: 0.8981\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.4035 - acc: 0.9074 - val_loss: 0.4251 - val_acc: 0.8889\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.3516 - acc: 0.9650 - val_loss: 0.4094 - val_acc: 0.9074\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3967 - acc: 0.9146 - val_loss: 0.4393 - val_acc: 0.8704\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3463 - acc: 0.9650 - val_loss: 0.5549 - val_acc: 0.7500\n",
      "Epoch 16\n",
      "972/972 [==============================] - 11s - loss: 0.4016 - acc: 0.9105 - val_loss: 0.3857 - val_acc: 0.9167\n",
      "Epoch 17\n",
      "972/972 [==============================] - 11s - loss: 0.3407 - acc: 0.9722 - val_loss: 0.3644 - val_acc: 0.9444\n",
      "Epoch 18\n",
      "972/972 [==============================] - 11s - loss: 0.3228 - acc: 0.9918 - val_loss: 0.4892 - val_acc: 0.8148\n",
      "Epoch 19\n",
      "972/972 [==============================] - 11s - loss: 0.3893 - acc: 0.9218 - val_loss: 0.4095 - val_acc: 0.8889\n",
      "Epoch 20\n",
      "972/972 [==============================] - 11s - loss: 0.3254 - acc: 0.9877 - val_loss: 0.3822 - val_acc: 0.9352\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3184 - acc: 0.9959 - val_loss: 0.3710 - val_acc: 0.9352\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3177 - acc: 0.9959 - val_loss: 0.3679 - val_acc: 0.9352\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3176 - acc: 0.9959 - val_loss: 0.3672 - val_acc: 0.9352\n",
      "Epoch 24\n",
      "972/972 [==============================] - 11s - loss: 0.3175 - acc: 0.9959 - val_loss: 0.3640 - val_acc: 0.9444\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3165 - acc: 0.9969 - val_loss: 0.4048 - val_acc: 0.9074\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.3827 - acc: 0.9270 - val_loss: 0.3786 - val_acc: 0.9352\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3457 - acc: 0.9671 - val_loss: 0.4493 - val_acc: 0.8796\n",
      "Epoch 28\n",
      "972/972 [==============================] - 11s - loss: 0.3432 - acc: 0.9691 - val_loss: 0.3620 - val_acc: 0.9537\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3571 - acc: 0.9558 - val_loss: 0.4213 - val_acc: 0.8889\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3285 - acc: 0.9856 - val_loss: 0.3423 - val_acc: 0.9722\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3180 - acc: 0.9949 - val_loss: 0.3503 - val_acc: 0.9630\n",
      "Epoch 32\n",
      "972/972 [==============================] - 12s - loss: 0.3152 - acc: 0.9979 - val_loss: 0.3497 - val_acc: 0.9630\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3150 - acc: 0.9979 - val_loss: 0.3458 - val_acc: 0.9630\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3448 - val_acc: 0.9630\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3438 - val_acc: 0.9722\n",
      "Epoch 36\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3473 - val_acc: 0.9630\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3476 - val_acc: 0.9630\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3469 - val_acc: 0.9630\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3143 - acc: 0.9990 - val_loss: 0.3425 - val_acc: 0.9722\n",
      "120/120 [==============================] - 0s\n",
      "[0.35560256242752075, 0.95833333333333337]\n",
      "120/120 [==============================] - 0s\n",
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 11s - loss: 0.6726 - acc: 0.5926 - val_loss: 0.6256 - val_acc: 0.7130\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6223 - acc: 0.6944 - val_loss: 0.6058 - val_acc: 0.7407\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.5863 - acc: 0.7634 - val_loss: 0.5503 - val_acc: 0.8426\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.6016 - acc: 0.7263 - val_loss: 0.6162 - val_acc: 0.7037\n",
      "Epoch 4\n",
      "972/972 [==============================] - 11s - loss: 0.5615 - acc: 0.7819 - val_loss: 0.5436 - val_acc: 0.7963\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.5932 - acc: 0.7243 - val_loss: 0.6211 - val_acc: 0.6667\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.5364 - acc: 0.7912 - val_loss: 0.5327 - val_acc: 0.7685\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.4722 - acc: 0.8570 - val_loss: 0.5235 - val_acc: 0.8148\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.4354 - acc: 0.8796 - val_loss: 0.5380 - val_acc: 0.7593\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.4275 - acc: 0.8909 - val_loss: 0.4165 - val_acc: 0.8981\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.4014 - acc: 0.9105 - val_loss: 0.4498 - val_acc: 0.8704\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.3996 - acc: 0.9115 - val_loss: 0.4925 - val_acc: 0.8148\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.4059 - acc: 0.9033 - val_loss: 0.3706 - val_acc: 0.9444\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.3777 - acc: 0.9311 - val_loss: 0.3641 - val_acc: 0.9537\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3427 - acc: 0.9753 - val_loss: 0.3582 - val_acc: 0.9444\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3304 - acc: 0.9846 - val_loss: 0.3575 - val_acc: 0.9444\n",
      "Epoch 16\n",
      "972/972 [==============================] - 11s - loss: 0.3254 - acc: 0.9897 - val_loss: 0.5388 - val_acc: 0.7593\n",
      "Epoch 17\n",
      "972/972 [==============================] - 11s - loss: 0.3837 - acc: 0.9280 - val_loss: 0.3795 - val_acc: 0.9352\n",
      "Epoch 18\n",
      "972/972 [==============================] - 11s - loss: 0.3268 - acc: 0.9877 - val_loss: 0.3553 - val_acc: 0.9630\n",
      "Epoch 19\n",
      "972/972 [==============================] - 11s - loss: 0.3228 - acc: 0.9907 - val_loss: 0.3694 - val_acc: 0.9352\n",
      "Epoch 20\n",
      "972/972 [==============================] - 11s - loss: 0.3200 - acc: 0.9938 - val_loss: 0.3654 - val_acc: 0.9352\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3198 - acc: 0.9938 - val_loss: 0.3612 - val_acc: 0.9444\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3187 - acc: 0.9949 - val_loss: 0.3899 - val_acc: 0.9167\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3767 - acc: 0.9372 - val_loss: 0.3480 - val_acc: 0.9722\n",
      "Epoch 24\n",
      "972/972 [==============================] - 11s - loss: 0.3202 - acc: 0.9938 - val_loss: 0.6223 - val_acc: 0.6759\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3774 - acc: 0.9321 - val_loss: 0.3768 - val_acc: 0.9259\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.3201 - acc: 0.9938 - val_loss: 0.3881 - val_acc: 0.9167\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3589 - acc: 0.9537 - val_loss: 0.3594 - val_acc: 0.9537\n",
      "Epoch 28\n",
      "972/972 [==============================] - 12s - loss: 0.3181 - acc: 0.9969 - val_loss: 0.3555 - val_acc: 0.9537\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3165 - acc: 0.9969 - val_loss: 0.3545 - val_acc: 0.9537\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3160 - acc: 0.9979 - val_loss: 0.3569 - val_acc: 0.9537\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3556 - val_acc: 0.9537\n",
      "Epoch 32\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3555 - val_acc: 0.9537\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3554 - val_acc: 0.9537\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3560 - val_acc: 0.9537\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3556 - val_acc: 0.9444\n",
      "Epoch 36\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3546 - val_acc: 0.9537\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3548 - val_acc: 0.9537\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3557 - val_acc: 0.9537\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3153 - acc: 0.9979 - val_loss: 0.3560 - val_acc: 0.9537\n",
      "120/120 [==============================] - 0s\n",
      "[0.33024638891220093, 0.98333333333333328]\n",
      "120/120 [==============================] - 0s\n",
      "(120L, 4400L)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 0\n",
      "972/972 [==============================] - 11s - loss: 0.6704 - acc: 0.5926 - val_loss: 0.6036 - val_acc: 0.7407\n",
      "Epoch 1\n",
      "972/972 [==============================] - 11s - loss: 0.6098 - acc: 0.7181 - val_loss: 0.6874 - val_acc: 0.6019\n",
      "Epoch 2\n",
      "972/972 [==============================] - 11s - loss: 0.6867 - acc: 0.6029 - val_loss: 0.6657 - val_acc: 0.6296\n",
      "Epoch 3\n",
      "972/972 [==============================] - 11s - loss: 0.6410 - acc: 0.6564 - val_loss: 0.6891 - val_acc: 0.5463\n",
      "Epoch 4\n",
      "972/972 [==============================] - 11s - loss: 0.6181 - acc: 0.6883 - val_loss: 0.6052 - val_acc: 0.7037\n",
      "Epoch 5\n",
      "972/972 [==============================] - 11s - loss: 0.5722 - acc: 0.7767 - val_loss: 0.5855 - val_acc: 0.7500\n",
      "Epoch 6\n",
      "972/972 [==============================] - 11s - loss: 0.5475 - acc: 0.8097 - val_loss: 0.5573 - val_acc: 0.7870\n",
      "Epoch 7\n",
      "972/972 [==============================] - 11s - loss: 0.5445 - acc: 0.7942 - val_loss: 0.5630 - val_acc: 0.7593\n",
      "Epoch 8\n",
      "972/972 [==============================] - 11s - loss: 0.5045 - acc: 0.8488 - val_loss: 0.6360 - val_acc: 0.6759\n",
      "Epoch 9\n",
      "972/972 [==============================] - 11s - loss: 0.5089 - acc: 0.8261 - val_loss: 0.6552 - val_acc: 0.6481\n",
      "Epoch 10\n",
      "972/972 [==============================] - 11s - loss: 0.4973 - acc: 0.8272 - val_loss: 0.4753 - val_acc: 0.8426\n",
      "Epoch 11\n",
      "972/972 [==============================] - 11s - loss: 0.4358 - acc: 0.8858 - val_loss: 0.4412 - val_acc: 0.8704\n",
      "Epoch 12\n",
      "972/972 [==============================] - 11s - loss: 0.4684 - acc: 0.8426 - val_loss: 0.4552 - val_acc: 0.8611\n",
      "Epoch 13\n",
      "972/972 [==============================] - 11s - loss: 0.4473 - acc: 0.8570 - val_loss: 0.4315 - val_acc: 0.8981\n",
      "Epoch 14\n",
      "972/972 [==============================] - 11s - loss: 0.3655 - acc: 0.9496 - val_loss: 0.4260 - val_acc: 0.8796\n",
      "Epoch 15\n",
      "972/972 [==============================] - 11s - loss: 0.3802 - acc: 0.9321 - val_loss: 0.4007 - val_acc: 0.9352\n",
      "Epoch 16\n",
      "972/972 [==============================] - 11s - loss: 0.3622 - acc: 0.9578 - val_loss: 0.4254 - val_acc: 0.8796\n",
      "Epoch 17\n",
      "972/972 [==============================] - 11s - loss: 0.3435 - acc: 0.9702 - val_loss: 0.3906 - val_acc: 0.9259\n",
      "Epoch 18\n",
      "972/972 [==============================] - 11s - loss: 0.3728 - acc: 0.9383 - val_loss: 0.4417 - val_acc: 0.8611\n",
      "Epoch 19\n",
      "972/972 [==============================] - 11s - loss: 0.3715 - acc: 0.9414 - val_loss: 0.3897 - val_acc: 0.9167\n",
      "Epoch 20\n",
      "972/972 [==============================] - 11s - loss: 0.3601 - acc: 0.9516 - val_loss: 0.4709 - val_acc: 0.8241\n",
      "Epoch 21\n",
      "972/972 [==============================] - 11s - loss: 0.3566 - acc: 0.9568 - val_loss: 0.3972 - val_acc: 0.9167\n",
      "Epoch 22\n",
      "972/972 [==============================] - 11s - loss: 0.3302 - acc: 0.9835 - val_loss: 0.3800 - val_acc: 0.9352\n",
      "Epoch 23\n",
      "972/972 [==============================] - 11s - loss: 0.3579 - acc: 0.9547 - val_loss: 0.3757 - val_acc: 0.9444\n",
      "Epoch 24\n",
      "972/972 [==============================] - 16s - loss: 0.3203 - acc: 0.9938 - val_loss: 0.3652 - val_acc: 0.9444\n",
      "Epoch 25\n",
      "972/972 [==============================] - 11s - loss: 0.3199 - acc: 0.9938 - val_loss: 0.3797 - val_acc: 0.9352\n",
      "Epoch 26\n",
      "972/972 [==============================] - 11s - loss: 0.3196 - acc: 0.9938 - val_loss: 0.3663 - val_acc: 0.9537\n",
      "Epoch 27\n",
      "972/972 [==============================] - 11s - loss: 0.3854 - acc: 0.9259 - val_loss: 0.4141 - val_acc: 0.8981\n",
      "Epoch 28\n",
      "972/972 [==============================] - 11s - loss: 0.3590 - acc: 0.9537 - val_loss: 0.3914 - val_acc: 0.9074\n",
      "Epoch 29\n",
      "972/972 [==============================] - 11s - loss: 0.3398 - acc: 0.9733 - val_loss: 0.3769 - val_acc: 0.9259\n",
      "Epoch 30\n",
      "972/972 [==============================] - 11s - loss: 0.3392 - acc: 0.9763 - val_loss: 0.3764 - val_acc: 0.9352\n",
      "Epoch 31\n",
      "972/972 [==============================] - 11s - loss: 0.3182 - acc: 0.9959 - val_loss: 0.3587 - val_acc: 0.9537\n",
      "Epoch 32\n",
      "972/972 [==============================] - 11s - loss: 0.3164 - acc: 0.9969 - val_loss: 0.3585 - val_acc: 0.9537\n",
      "Epoch 33\n",
      "972/972 [==============================] - 11s - loss: 0.3155 - acc: 0.9979 - val_loss: 0.3546 - val_acc: 0.9537\n",
      "Epoch 34\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3542 - val_acc: 0.9630\n",
      "Epoch 35\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3541 - val_acc: 0.9537\n",
      "Epoch 36\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3541 - val_acc: 0.9537\n",
      "Epoch 37\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3543 - val_acc: 0.9537\n",
      "Epoch 38\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3544 - val_acc: 0.9537\n",
      "Epoch 39\n",
      "972/972 [==============================] - 11s - loss: 0.3154 - acc: 0.9979 - val_loss: 0.3539 - val_acc: 0.9537\n",
      "120/120 [==============================] - 0s\n",
      "[0.32670316100120544, 0.98333333333333328]\n",
      "120/120 [==============================] - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:69: DeprecationWarning: The indices parameter is deprecated and will be removed (assumed True) in 0.17\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, cross_validation, grid_search\n",
    "all_results = []\n",
    "kf_total = cross_validation.KFold(shuffeled_samples.shape[0], n_folds=10, indices=True, shuffle=True, random_state=4)\n",
    "for train, test in kf_total:\n",
    "    \n",
    "    model2.set_weights(original_weights)\n",
    "    data_traing_lstm = shuffeled_samples[train].reshape(shuffeled_samples[train].shape[0],number_of_channels,-1).transpose(0,2,1)\n",
    "    print (shuffeled_samples[test].shape)\n",
    "    train_tags = suffule_tags[train]\n",
    "\n",
    "    data_testing_lstm = shuffeled_samples[test].reshape(shuffeled_samples[test].shape[0],number_of_channels,-1).transpose(0,2,1)\n",
    "    test_tags = suffule_tags[test]\n",
    "\n",
    "    model2.set_weights(original_weights)\n",
    "    model2.fit(data_traing_lstm, train_tags, nb_epoch=40,show_accuracy=True,verbose=1, validation_split=0.1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    print (model2.evaluate(data_testing_lstm, test_tags, show_accuracy=True,verbose=1) )\n",
    "    all_results.append(model2.evaluate(data_testing_lstm, test_tags, show_accuracy=True,verbose=1)) \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "#     print train, '\\n', test, '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970833333333\n"
     ]
    }
   ],
   "source": [
    "print (np.mean( np.asarray(all_results)[:,1] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960L, 80L, 55L)\n",
      "Epoch 0\n",
      "960/960 [==============================] - 11s - loss: 0.4000 - acc: 0.9125    \n",
      "Epoch 1\n",
      "960/960 [==============================] - 10s - loss: 0.3682 - acc: 0.9417    \n",
      "<keras.callbacks.History object at 0x00000000454A10B8>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (data_traing_lstm.transpose(0,2,1). shape)\n",
    "print model.fit(data_traing_lstm.transpose(0,2,1), b_train, nb_epoch=2,show_accuracy=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s     \n",
      "[0.37834412852923077, 0.93333333333333335]\n"
     ]
    }
   ],
   "source": [
    "print model.evaluate(data_testing_lstm.transpose(0,2,1), b_test,show_accuracy=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\keras-0.1.1-py2.7.egg\\keras\\__init__.pyc\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import keras\n",
    "\n",
    "print os.path.abspath(keras.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0.3026033043861389, dtype=float32), array(0.7954545454545454)]\n"
     ]
    }
   ],
   "source": [
    "print model.test(a_test, b_test, accuracy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
